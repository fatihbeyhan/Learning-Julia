{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP541 | Deep Learning Lab 1\n",
    "\n",
    "## First lab session practice!       \n",
    "\n",
    "### 15 June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this exercise, you’re supposed to preprocess **Boston Housing Dataset**, so that we can use it in some machine learning models like linear regression later.\n",
    "\n",
    "* The housing dataset has housing related information for 506 neighborhoods in Boston from 1978. Each neighborhood is represented using **13 attributes** such as crime rate or distance to employment centers. The goal is to predict the median value of the houses given in $1000's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use some necessary functions, we need to import some modules. Just insert the following line as first line or cell,\n",
    "* *using DelimitedFiles, Statistics, Random*\n",
    "\n",
    "**Statistics** contains statistical procedures like *mean* and *std*, **DelimitedFiles** contains our data read procedure functions (*readdlm*) and **Random** is for random numbers (*rand, Random.seed!* etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles, Statistics, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First download, and then read the file. \n",
    "* You need to download the data within Julia notebook (please have a look: readdlm, download functions of Julia by typing e.g. @doc download). \n",
    "* If you look at the data, you see that each house is represented with 13 attributes separated by whitespaces and there are 506 lines in total. Here’s the link to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "download(url::AbstractString, [localfile::AbstractString])\n",
       "\\end{verbatim}\n",
       "Download a file from the given url, optionally renaming it to the given local file name. If no filename is given this will download into a randomly-named file in your temp directory. Note that this function relies on the availability of external tools such as \\texttt{curl}, \\texttt{wget} or \\texttt{fetch} to download the file and is provided for convenience. For production use or situations in which more options are needed, please use a package that provides the desired functionality instead.\n",
       "\n",
       "Returns the filename of the downloaded file.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "download(url::AbstractString, [localfile::AbstractString])\n",
       "```\n",
       "\n",
       "Download a file from the given url, optionally renaming it to the given local file name. If no filename is given this will download into a randomly-named file in your temp directory. Note that this function relies on the availability of external tools such as `curl`, `wget` or `fetch` to download the file and is provided for convenience. For production use or situations in which more options are needed, please use a package that provides the desired functionality instead.\n",
       "\n",
       "Returns the filename of the downloaded file.\n"
      ],
      "text/plain": [
       "\u001b[36m  download(url::AbstractString, [localfile::AbstractString])\u001b[39m\n",
       "\n",
       "  Download a file from the given url, optionally renaming it to the given\n",
       "  local file name. If no filename is given this will download into a\n",
       "  randomly-named file in your temp directory. Note that this function relies\n",
       "  on the availability of external tools such as \u001b[36mcurl\u001b[39m, \u001b[36mwget\u001b[39m or \u001b[36mfetch\u001b[39m to\n",
       "  download the file and is provided for convenience. For production use or\n",
       "  situations in which more options are needed, please use a package that\n",
       "  provides the desired functionality instead.\n",
       "\n",
       "  Returns the filename of the downloaded file."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\FATIHB~1\\\\AppData\\\\Local\\\\Temp\\\\jl_AE2F.tmp\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = download(\"https://raw.githubusercontent.com/ilkerkesen/ufldl-tutorial/master/ex1/housing.data\") # download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506×14 Array{Float64,2}:\n",
       " 0.00632  18.0   2.31  0.0  0.538  6.575  …  296.0  15.3  396.9    4.98  24.0\n",
       " 0.02731   0.0   7.07  0.0  0.469  6.421     242.0  17.8  396.9    9.14  21.6\n",
       " 0.02729   0.0   7.07  0.0  0.469  7.185     242.0  17.8  392.83   4.03  34.7\n",
       " 0.03237   0.0   2.18  0.0  0.458  6.998     222.0  18.7  394.63   2.94  33.4\n",
       " 0.06905   0.0   2.18  0.0  0.458  7.147     222.0  18.7  396.9    5.33  36.2\n",
       " 0.02985   0.0   2.18  0.0  0.458  6.43   …  222.0  18.7  394.12   5.21  28.7\n",
       " 0.08829  12.5   7.87  0.0  0.524  6.012     311.0  15.2  395.6   12.43  22.9\n",
       " 0.14455  12.5   7.87  0.0  0.524  6.172     311.0  15.2  396.9   19.15  27.1\n",
       " 0.21124  12.5   7.87  0.0  0.524  5.631     311.0  15.2  386.63  29.93  16.5\n",
       " 0.17004  12.5   7.87  0.0  0.524  6.004     311.0  15.2  386.71  17.1   18.9\n",
       " 0.22489  12.5   7.87  0.0  0.524  6.377  …  311.0  15.2  392.52  20.45  15.0\n",
       " 0.11747  12.5   7.87  0.0  0.524  6.009     311.0  15.2  396.9   13.27  18.9\n",
       " 0.09378  12.5   7.87  0.0  0.524  5.889     311.0  15.2  390.5   15.71  21.7\n",
       " ⋮                                 ⋮      ⋱          ⋮                       \n",
       " 0.27957   0.0   9.69  0.0  0.585  5.926     391.0  19.2  396.9   13.59  24.5\n",
       " 0.17899   0.0   9.69  0.0  0.585  5.67   …  391.0  19.2  393.29  17.6   23.1\n",
       " 0.2896    0.0   9.69  0.0  0.585  5.39      391.0  19.2  396.9   21.14  19.7\n",
       " 0.26838   0.0   9.69  0.0  0.585  5.794     391.0  19.2  396.9   14.1   18.3\n",
       " 0.23912   0.0   9.69  0.0  0.585  6.019     391.0  19.2  396.9   12.92  21.2\n",
       " 0.17783   0.0   9.69  0.0  0.585  5.569     391.0  19.2  395.77  15.1   17.5\n",
       " 0.22438   0.0   9.69  0.0  0.585  6.027  …  391.0  19.2  396.9   14.33  16.8\n",
       " 0.06263   0.0  11.93  0.0  0.573  6.593     273.0  21.0  391.99   9.67  22.4\n",
       " 0.04527   0.0  11.93  0.0  0.573  6.12      273.0  21.0  396.9    9.08  20.6\n",
       " 0.06076   0.0  11.93  0.0  0.573  6.976     273.0  21.0  396.9    5.64  23.9\n",
       " 0.10959   0.0  11.93  0.0  0.573  6.794     273.0  21.0  393.45   6.48  22.0\n",
       " 0.04741   0.0  11.93  0.0  0.573  6.03   …  273.0  21.0  396.9    7.88  11.9"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to read the data\n",
    "data = readdlm(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's a matrix of the size 506x14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The resulting data matrix should have 506 rows representing neighborhoods and 14 columns representing the attributes. \n",
    "* **The last attribute is the median house price to be predicted, so let’s separate it.** \n",
    "* Also, take transpose of this data matrix to make data convenient with common mathematical notation (deep learning people represent instances/samples as column vectors mostly). \n",
    "\n",
    "We will use Julia’s array indexing operation to split the data array into input x and output y. (Hint: you may want to reshape y array into a matrix with size 1x506, use reshape procedure for this purpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×506 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n",
       "   0.00632    0.02731    0.02729  …    0.06076    0.10959    0.04741\n",
       "  18.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   2.31       7.07       7.07         11.93      11.93      11.93   \n",
       "   0.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   0.538      0.469      0.469         0.573      0.573      0.573  \n",
       "   6.575      6.421      7.185    …    6.976      6.794      6.03   \n",
       "  65.2       78.9       61.1          91.0       89.3       80.8    \n",
       "   4.09       4.9671     4.9671        2.1675     2.3889     2.505  \n",
       "   1.0        2.0        2.0           1.0        1.0        1.0    \n",
       " 296.0      242.0      242.0         273.0      273.0      273.0    \n",
       "  15.3       17.8       17.8      …   21.0       21.0       21.0    \n",
       " 396.9      396.9      392.83        396.9      393.45     396.9    \n",
       "   4.98       9.14       4.03          5.64       6.48       7.88   "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data[:,end]\n",
    "input = data[:,1:end-1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "reshape(A, dims...) -> AbstractArray\n",
       "reshape(A, dims) -> AbstractArray\n",
       "\\end{verbatim}\n",
       "Return an array with the same data as \\texttt{A}, but with different dimension sizes or number of dimensions. The two arrays share the same underlying data, so that the result is mutable if and only if \\texttt{A} is mutable, and setting elements of one alters the values of the other.\n",
       "\n",
       "The new dimensions may be specified either as a list of arguments or as a shape tuple. At most one dimension may be specified with a \\texttt{:}, in which case its length is computed such that its product with all the specified dimensions is equal to the length of the original array \\texttt{A}. The total number of elements must not change.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> A = Vector(1:16)\n",
       "16-element Array{Int64,1}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       "\n",
       "julia> reshape(A, (4, 4))\n",
       "4×4 Array{Int64,2}:\n",
       " 1  5   9  13\n",
       " 2  6  10  14\n",
       " 3  7  11  15\n",
       " 4  8  12  16\n",
       "\n",
       "julia> reshape(A, 2, :)\n",
       "2×8 Array{Int64,2}:\n",
       " 1  3  5  7   9  11  13  15\n",
       " 2  4  6  8  10  12  14  16\n",
       "\n",
       "julia> reshape(1:6, 2, 3)\n",
       "2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64:\n",
       " 1  3  5\n",
       " 2  4  6\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "reshape(A, dims...) -> AbstractArray\n",
       "reshape(A, dims) -> AbstractArray\n",
       "```\n",
       "\n",
       "Return an array with the same data as `A`, but with different dimension sizes or number of dimensions. The two arrays share the same underlying data, so that the result is mutable if and only if `A` is mutable, and setting elements of one alters the values of the other.\n",
       "\n",
       "The new dimensions may be specified either as a list of arguments or as a shape tuple. At most one dimension may be specified with a `:`, in which case its length is computed such that its product with all the specified dimensions is equal to the length of the original array `A`. The total number of elements must not change.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = Vector(1:16)\n",
       "16-element Array{Int64,1}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       "\n",
       "julia> reshape(A, (4, 4))\n",
       "4×4 Array{Int64,2}:\n",
       " 1  5   9  13\n",
       " 2  6  10  14\n",
       " 3  7  11  15\n",
       " 4  8  12  16\n",
       "\n",
       "julia> reshape(A, 2, :)\n",
       "2×8 Array{Int64,2}:\n",
       " 1  3  5  7   9  11  13  15\n",
       " 2  4  6  8  10  12  14  16\n",
       "\n",
       "julia> reshape(1:6, 2, 3)\n",
       "2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64:\n",
       " 1  3  5\n",
       " 2  4  6\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  reshape(A, dims...) -> AbstractArray\u001b[39m\n",
       "\u001b[36m  reshape(A, dims) -> AbstractArray\u001b[39m\n",
       "\n",
       "  Return an array with the same data as \u001b[36mA\u001b[39m, but with different dimension sizes\n",
       "  or number of dimensions. The two arrays share the same underlying data, so\n",
       "  that the result is mutable if and only if \u001b[36mA\u001b[39m is mutable, and setting elements\n",
       "  of one alters the values of the other.\n",
       "\n",
       "  The new dimensions may be specified either as a list of arguments or as a\n",
       "  shape tuple. At most one dimension may be specified with a \u001b[36m:\u001b[39m, in which case\n",
       "  its length is computed such that its product with all the specified\n",
       "  dimensions is equal to the length of the original array \u001b[36mA\u001b[39m. The total number\n",
       "  of elements must not change.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = Vector(1:16)\u001b[39m\n",
       "\u001b[36m  16-element Array{Int64,1}:\u001b[39m\n",
       "\u001b[36m    1\u001b[39m\n",
       "\u001b[36m    2\u001b[39m\n",
       "\u001b[36m    3\u001b[39m\n",
       "\u001b[36m    4\u001b[39m\n",
       "\u001b[36m    5\u001b[39m\n",
       "\u001b[36m    6\u001b[39m\n",
       "\u001b[36m    7\u001b[39m\n",
       "\u001b[36m    8\u001b[39m\n",
       "\u001b[36m    9\u001b[39m\n",
       "\u001b[36m   10\u001b[39m\n",
       "\u001b[36m   11\u001b[39m\n",
       "\u001b[36m   12\u001b[39m\n",
       "\u001b[36m   13\u001b[39m\n",
       "\u001b[36m   14\u001b[39m\n",
       "\u001b[36m   15\u001b[39m\n",
       "\u001b[36m   16\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> reshape(A, (4, 4))\u001b[39m\n",
       "\u001b[36m  4×4 Array{Int64,2}:\u001b[39m\n",
       "\u001b[36m   1  5   9  13\u001b[39m\n",
       "\u001b[36m   2  6  10  14\u001b[39m\n",
       "\u001b[36m   3  7  11  15\u001b[39m\n",
       "\u001b[36m   4  8  12  16\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> reshape(A, 2, :)\u001b[39m\n",
       "\u001b[36m  2×8 Array{Int64,2}:\u001b[39m\n",
       "\u001b[36m   1  3  5  7   9  11  13  15\u001b[39m\n",
       "\u001b[36m   2  4  6  8  10  12  14  16\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> reshape(1:6, 2, 3)\u001b[39m\n",
       "\u001b[36m  2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64:\u001b[39m\n",
       "\u001b[36m   1  3  5\u001b[39m\n",
       "\u001b[36m   2  4  6\u001b[39m"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×506 Array{Float64,2}:\n",
       " 24.0  21.6  34.7  33.4  36.2  28.7  …  16.8  22.4  20.6  23.9  22.0  11.9"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = reshape(target,(1,506))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, input attributes have different ranges. \n",
    "* We need to normalize attributes by **subtracting their mean and then dividing by their standard deviation** (hint: take means and standard deviations of row vectors). \n",
    "* The ***mean*** and ***std*** functions calculate mean and standard deviation values of x. Calculate mean and standard deviation values. Perform normalization on input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×506 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n",
       "   0.00632    0.02731    0.02729  …    0.06076    0.10959    0.04741\n",
       "  18.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   2.31       7.07       7.07         11.93      11.93      11.93   \n",
       "   0.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   0.538      0.469      0.469         0.573      0.573      0.573  \n",
       "   6.575      6.421      7.185    …    6.976      6.794      6.03   \n",
       "  65.2       78.9       61.1          91.0       89.3       80.8    \n",
       "   4.09       4.9671     4.9671        2.1675     2.3889     2.505  \n",
       "   1.0        2.0        2.0           1.0        1.0        1.0    \n",
       " 296.0      242.0      242.0         273.0      273.0      273.0    \n",
       "  15.3       17.8       17.8      …   21.0       21.0       21.0    \n",
       " 396.9      396.9      392.83        396.9      393.45     396.9    \n",
       "   4.98       9.14       4.03          5.64       6.48       7.88   "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×506 Array{Float64,2}:\n",
       " 0.00632  0.02731  0.02729  0.03237  …  0.04527  0.06076  0.10959  0.04741"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.60154510533249, 3.6135235573122535)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std(input[1,:]),mean(input[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_index in 1:506\n",
    "    column = input[:,column_index]\n",
    "    s = std(column)\n",
    "    m = mean(column)\n",
    "    \n",
    "    input[:,column_index] = (column.-m)./s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×506 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n",
       " -0.483768   -0.483736  -0.470793   …  -0.494178  -0.494467  -0.489905\n",
       " -0.344203   -0.48396   -0.471019      -0.49466   -0.495343  -0.490282\n",
       " -0.4659     -0.425868  -0.412476      -0.399977  -0.400032  -0.395432\n",
       " -0.483817   -0.48396   -0.471019      -0.49466   -0.495343  -0.490282\n",
       " -0.479644   -0.480107  -0.467135      -0.490112  -0.490765  -0.485726\n",
       " -0.432819   -0.431201  -0.411523   …  -0.439294  -0.441065  -0.44234 \n",
       "  0.0218972   0.164338   0.0349192      0.227567   0.218088   0.152121\n",
       " -0.452094   -0.443147  -0.429889      -0.477457  -0.476258  -0.470366\n",
       " -0.476061   -0.467527  -0.454458      -0.486723  -0.487354  -0.482331\n",
       "  1.81206     1.50448    1.53286        1.67202    1.68569    1.68021 \n",
       " -0.365145   -0.337703  -0.323626   …  -0.327992  -0.327571  -0.323321\n",
       "  2.59468     2.77725    2.78181        2.65536    2.64799    2.66528 \n",
       " -0.44519    -0.40886   -0.437648      -0.449898  -0.443573  -0.427632"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to split our dataset into training and test subsets so we can estimate how good our model will perform on unseen data. \n",
    "\n",
    "There are 506 house in our dataset. Let’s take **400** of them randomly, use them as training data. Let the rest be test data.\n",
    "\n",
    "**In the end, you will have 4 different arrays: xtrn, ytrn, xtst and ytst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "seed!([rng=GLOBAL_RNG], seed) -> rng\n",
       "seed!([rng=GLOBAL_RNG]) -> rng\n",
       "\\end{verbatim}\n",
       "Reseed the random number generator: \\texttt{rng} will give a reproducible sequence of numbers if and only if a \\texttt{seed} is provided. Some RNGs don't accept a seed, like \\texttt{RandomDevice}. After the call to \\texttt{seed!}, \\texttt{rng} is equivalent to a newly created object initialized with the same seed.\n",
       "\n",
       "If \\texttt{rng} is not specified, it defaults to seeding the state of the shared thread-local generator.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> Random.seed!(1234);\n",
       "\n",
       "julia> x1 = rand(2)\n",
       "2-element Array{Float64,1}:\n",
       " 0.590845\n",
       " 0.766797\n",
       "\n",
       "julia> Random.seed!(1234);\n",
       "\n",
       "julia> x2 = rand(2)\n",
       "2-element Array{Float64,1}:\n",
       " 0.590845\n",
       " 0.766797\n",
       "\n",
       "julia> x1 == x2\n",
       "true\n",
       "\n",
       "julia> rng = MersenneTwister(1234); rand(rng, 2) == x1\n",
       "true\n",
       "\n",
       "julia> MersenneTwister(1) == Random.seed!(rng, 1)\n",
       "true\n",
       "\n",
       "julia> rand(Random.seed!(rng), Bool) # not reproducible\n",
       "true\n",
       "\n",
       "julia> rand(Random.seed!(rng), Bool)\n",
       "false\n",
       "\n",
       "julia> rand(MersenneTwister(), Bool) # not reproducible either\n",
       "true\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "seed!([rng=GLOBAL_RNG], seed) -> rng\n",
       "seed!([rng=GLOBAL_RNG]) -> rng\n",
       "```\n",
       "\n",
       "Reseed the random number generator: `rng` will give a reproducible sequence of numbers if and only if a `seed` is provided. Some RNGs don't accept a seed, like `RandomDevice`. After the call to `seed!`, `rng` is equivalent to a newly created object initialized with the same seed.\n",
       "\n",
       "If `rng` is not specified, it defaults to seeding the state of the shared thread-local generator.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```julia-repl\n",
       "julia> Random.seed!(1234);\n",
       "\n",
       "julia> x1 = rand(2)\n",
       "2-element Array{Float64,1}:\n",
       " 0.590845\n",
       " 0.766797\n",
       "\n",
       "julia> Random.seed!(1234);\n",
       "\n",
       "julia> x2 = rand(2)\n",
       "2-element Array{Float64,1}:\n",
       " 0.590845\n",
       " 0.766797\n",
       "\n",
       "julia> x1 == x2\n",
       "true\n",
       "\n",
       "julia> rng = MersenneTwister(1234); rand(rng, 2) == x1\n",
       "true\n",
       "\n",
       "julia> MersenneTwister(1) == Random.seed!(rng, 1)\n",
       "true\n",
       "\n",
       "julia> rand(Random.seed!(rng), Bool) # not reproducible\n",
       "true\n",
       "\n",
       "julia> rand(Random.seed!(rng), Bool)\n",
       "false\n",
       "\n",
       "julia> rand(MersenneTwister(), Bool) # not reproducible either\n",
       "true\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  seed!([rng=GLOBAL_RNG], seed) -> rng\u001b[39m\n",
       "\u001b[36m  seed!([rng=GLOBAL_RNG]) -> rng\u001b[39m\n",
       "\n",
       "  Reseed the random number generator: \u001b[36mrng\u001b[39m will give a reproducible sequence of\n",
       "  numbers if and only if a \u001b[36mseed\u001b[39m is provided. Some RNGs don't accept a seed,\n",
       "  like \u001b[36mRandomDevice\u001b[39m. After the call to \u001b[36mseed!\u001b[39m, \u001b[36mrng\u001b[39m is equivalent to a newly\n",
       "  created object initialized with the same seed.\n",
       "\n",
       "  If \u001b[36mrng\u001b[39m is not specified, it defaults to seeding the state of the shared\n",
       "  thread-local generator.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> Random.seed!(1234);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> x1 = rand(2)\u001b[39m\n",
       "\u001b[36m  2-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m   0.590845\u001b[39m\n",
       "\u001b[36m   0.766797\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Random.seed!(1234);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> x2 = rand(2)\u001b[39m\n",
       "\u001b[36m  2-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m   0.590845\u001b[39m\n",
       "\u001b[36m   0.766797\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> x1 == x2\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> rng = MersenneTwister(1234); rand(rng, 2) == x1\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> MersenneTwister(1) == Random.seed!(rng, 1)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> rand(Random.seed!(rng), Bool) # not reproducible\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> rand(Random.seed!(rng), Bool)\u001b[39m\n",
       "\u001b[36m  false\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> rand(MersenneTwister(), Bool) # not reproducible either\u001b[39m\n",
       "\u001b[36m  true\u001b[39m"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc Random.seed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x00000001], Random.DSFMT.DSFMT_state(Int32[1749029653, 1072851681, 1610647787, 1072862326, 1841712345, 1073426746, -198061126, 1073322060, -156153802, 1073567984  …  1977574422, 1073209915, 278919868, 1072835605, 1290372147, 18858467, 1815133874, -1716870370, 382, 0]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt128[0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000  …  0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000], 1002, 0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "randperm([rng=GLOBAL_RNG,] n::Integer)\n",
       "\\end{verbatim}\n",
       "Construct a random permutation of length \\texttt{n}. The optional \\texttt{rng} argument specifies a random number generator (see \\href{@ref}{Random Numbers}). The element type of the result is the same as the type of \\texttt{n}.\n",
       "\n",
       "To randomly permute an arbitrary vector, see \\href{@ref}{\\texttt{shuffle}} or \\href{@ref}{\\texttt{shuffle!}}.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{compat}\n",
       "\n",
       "Julia 1.1\n",
       "\n",
       "In Julia 1.1 \\texttt{randperm} returns a vector \\texttt{v} with \\texttt{eltype(v) == typeof(n)} while in Julia 1.0 \\texttt{eltype(v) == Int}.\n",
       "\n",
       "\\end{quote}\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> randperm(MersenneTwister(1234), 4)\n",
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 1\n",
       " 4\n",
       " 3\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "randperm([rng=GLOBAL_RNG,] n::Integer)\n",
       "```\n",
       "\n",
       "Construct a random permutation of length `n`. The optional `rng` argument specifies a random number generator (see [Random Numbers](@ref)). The element type of the result is the same as the type of `n`.\n",
       "\n",
       "To randomly permute an arbitrary vector, see [`shuffle`](@ref) or [`shuffle!`](@ref).\n",
       "\n",
       "!!! compat \"Julia 1.1\"\n",
       "    In Julia 1.1 `randperm` returns a vector `v` with `eltype(v) == typeof(n)` while in Julia 1.0 `eltype(v) == Int`.\n",
       "\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> randperm(MersenneTwister(1234), 4)\n",
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 1\n",
       " 4\n",
       " 3\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  randperm([rng=GLOBAL_RNG,] n::Integer)\u001b[39m\n",
       "\n",
       "  Construct a random permutation of length \u001b[36mn\u001b[39m. The optional \u001b[36mrng\u001b[39m argument\n",
       "  specifies a random number generator (see Random Numbers). The element type\n",
       "  of the result is the same as the type of \u001b[36mn\u001b[39m.\n",
       "\n",
       "  To randomly permute an arbitrary vector, see \u001b[36mshuffle\u001b[39m or \u001b[36mshuffle!\u001b[39m.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.1\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  In Julia 1.1 \u001b[36mrandperm\u001b[39m returns a vector \u001b[36mv\u001b[39m with \u001b[36meltype(v) ==\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  typeof(n)\u001b[39m while in Julia 1.0 \u001b[36meltype(v) == Int\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> randperm(MersenneTwister(1234), 4)\u001b[39m\n",
       "\u001b[36m  4-element Array{Int64,1}:\u001b[39m\n",
       "\u001b[36m   2\u001b[39m\n",
       "\u001b[36m   1\u001b[39m\n",
       "\u001b[36m   4\u001b[39m\n",
       "\u001b[36m   3\u001b[39m"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc randperm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×400 Array{Float64,2}:\n",
       " -0.480773  -0.45548   -0.482986  …  -0.485203   -0.499224  -0.48524  \n",
       " -0.481495  -0.477348  -0.212065     -0.0786389  -0.500116  -0.485902 \n",
       " -0.460114  -0.395201  -0.4364       -0.474229   -0.440443  -0.420256 \n",
       " -0.481495  -0.477348  -0.483375     -0.485695   -0.500116  -0.485902 \n",
       " -0.477253  -0.472834  -0.47998      -0.482906   -0.496491  -0.482315 \n",
       " -0.432789  -0.436084  -0.439144  …  -0.445776   -0.454985  -0.441864 \n",
       "  0.298975  -0.163695  -0.263227     -0.360186    0.176787   0.0492357\n",
       " -0.455526  -0.456443  -0.431898     -0.413033   -0.483156  -0.468343 \n",
       " -0.455421  -0.444157  -0.475623     -0.458558   -0.46526   -0.446553 \n",
       "  1.19591    2.04515    1.87314       2.30264     2.17682    2.34718  \n",
       " -0.326791  -0.324671  -0.352371  …  -0.361543   -0.354418  -0.369168 \n",
       "  2.91677    2.43058    2.57095       2.17598     2.25518    2.1084   \n",
       " -0.359992  -0.372465  -0.387021     -0.432845   -0.41458   -0.419272 "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(1)\n",
    "indexes = randperm(506)\n",
    "\n",
    "xtrn, ytrn, xtst, ytst = input[:,indexes[1:400]],target[:,indexes[1:400]],input[:,indexes[401:end]],target[:,indexes[401:end]]\n",
    "\n",
    "xtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×400 Array{Float64,2}:\n",
       " 26.4  16.1  17.1  19.0  21.7  17.4  …  23.9  18.3  8.8  18.6  19.8  22.8"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×106 Array{Float64,2}:\n",
       " -0.500386  -0.362399  -0.491272  …  -0.441134   -0.485236   -0.479284\n",
       " -0.501035  -0.441211  -0.236055     -0.469329   -0.486341   -0.166252\n",
       " -0.268878  -0.342412  -0.445776     -0.379669   -0.377197   -0.456165\n",
       " -0.501035  -0.441211  -0.491538     -0.469329   -0.486341   -0.480162\n",
       " -0.495776  -0.437952  -0.488284     -0.466441   -0.482915   -0.477113\n",
       " -0.446693  -0.403809  -0.442019  …  -0.439043   -0.440943   -0.434429\n",
       "  0.260149   0.104638  -0.187965     -0.0740346  -0.0315732  -0.277167\n",
       " -0.481146  -0.433211  -0.450272     -0.451764   -0.436787   -0.448305\n",
       " -0.482933  -0.310207  -0.438938     -0.350443   -0.454978   -0.445283\n",
       "  1.20054    3.19414    1.98063       2.82974     1.77966     2.2962  \n",
       " -0.328162  -0.330949  -0.370559  …  -0.369267   -0.360888   -0.37413 \n",
       "  2.91723    0.537824   2.4822        1.47583     2.62568     2.19044 \n",
       " -0.371878  -0.333242  -0.420153     -0.395124   -0.362143   -0.448352"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×106 Array{Float64,2}:\n",
       " 20.3  27.5  22.0  30.7  19.4  24.5  …  24.8  42.3  16.3  19.1  20.3  29.8"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our data is ready to be used. This week, we will not deal with the training of a model, but let’s look at how good a randomly initialized linear regression model performs on our processed data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basically, we need to use some weights with whom we’re going to multiply the attributes of houses so that we can predict the price of that house. Neighborhoods are represented with 13 attributes and we need to predict the prices which is a single number. We need to have a **weight matrices with size of 1x13.** We also use a **bias value which is 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To create weight matrix, we will sample from normal distribution with zero mean and a small standard deviation. \n",
    "* In this tutorial, our standard deviation value is equal to **0.1**. Use *randn* function to create a random weight matrix whose values are sampled from a unit normal distribution (mean=0, standard deviation=1). \n",
    "* Multiply our weight matrix by 0.1 which is our desired standard deviation. We will not use bias in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\n",
       "\\end{verbatim}\n",
       "Generate a normally-distributed random number of type \\texttt{T} with mean 0 and standard deviation 1. Optionally generate an array of normally-distributed random numbers. The \\texttt{Base} module currently provides an implementation for the types \\href{@ref}{\\texttt{Float16}}, \\href{@ref}{\\texttt{Float32}}, and \\href{@ref}{\\texttt{Float64}} (the default), and their \\href{@ref}{\\texttt{Complex}} counterparts. When the type argument is complex, the values are drawn from the circularly symmetric complex normal distribution of variance 1 (corresponding to real and imaginary part having independent normal distribution with mean zero and variance \\texttt{1/2}).\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> using Random\n",
       "\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randn(rng, ComplexF64)\n",
       "0.6133070881429037 - 0.6376291670853887im\n",
       "\n",
       "julia> randn(rng, ComplexF32, (2, 3))\n",
       "2×3 Array{Complex{Float32},2}:\n",
       " -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\n",
       "  0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\n",
       "```\n",
       "\n",
       "Generate a normally-distributed random number of type `T` with mean 0 and standard deviation 1. Optionally generate an array of normally-distributed random numbers. The `Base` module currently provides an implementation for the types [`Float16`](@ref), [`Float32`](@ref), and [`Float64`](@ref) (the default), and their [`Complex`](@ref) counterparts. When the type argument is complex, the values are drawn from the circularly symmetric complex normal distribution of variance 1 (corresponding to real and imaginary part having independent normal distribution with mean zero and variance `1/2`).\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> using Random\n",
       "\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randn(rng, ComplexF64)\n",
       "0.6133070881429037 - 0.6376291670853887im\n",
       "\n",
       "julia> randn(rng, ComplexF32, (2, 3))\n",
       "2×3 Array{Complex{Float32},2}:\n",
       " -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\n",
       "  0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\u001b[39m\n",
       "\n",
       "  Generate a normally-distributed random number of type \u001b[36mT\u001b[39m with mean 0 and\n",
       "  standard deviation 1. Optionally generate an array of normally-distributed\n",
       "  random numbers. The \u001b[36mBase\u001b[39m module currently provides an implementation for the\n",
       "  types \u001b[36mFloat16\u001b[39m, \u001b[36mFloat32\u001b[39m, and \u001b[36mFloat64\u001b[39m (the default), and their \u001b[36mComplex\u001b[39m\n",
       "  counterparts. When the type argument is complex, the values are drawn from\n",
       "  the circularly symmetric complex normal distribution of variance 1\n",
       "  (corresponding to real and imaginary part having independent normal\n",
       "  distribution with mean zero and variance \u001b[36m1/2\u001b[39m).\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> using Random\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> rng = MersenneTwister(1234);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> randn(rng, ComplexF64)\u001b[39m\n",
       "\u001b[36m  0.6133070881429037 - 0.6376291670853887im\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> randn(rng, ComplexF32, (2, 3))\u001b[39m\n",
       "\u001b[36m  2×3 Array{Complex{Float32},2}:\u001b[39m\n",
       "\u001b[36m   -0.349649-0.638457im  0.376756-0.192146im  -0.396334-0.0136413im\u001b[39m\n",
       "\u001b[36m    0.611224+1.56403im   0.355204-0.365563im  0.0905552+1.31012im\u001b[39m"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×13 Array{Float64,2}:\n",
       " -0.0197354  0.0737622  0.0479149  …  0.0148911  -0.0221678  0.0131052"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = reshape(randn(13).*(0.1),(1,13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we have input and weights.** \n",
    "**Let’s write a function to predict price.** \n",
    "\n",
    "* Implement a function takes weight matrix and neighborhood attributes as input and outputs a single value, house price prediction. \n",
    "\n",
    "\n",
    "* **Simply perform a matrix multiplication inside this function and return the output vector. We call this function as predict function.**\n",
    "\n",
    "\n",
    "* Call predict function and store the output as ypred.\n",
    "\n",
    "\n",
    "* ypred is an 1x400 dimensional array/matrix. Each value in this array is the model’s price prediction for an average house in corresponding neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×400 Array{Float64,2}:\n",
       " -0.0650817  -0.057373  -0.0310276  …  -0.0231113  -0.0740885  -0.0724072"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have inputs with 13x506 dim and weights with 1x13 dims we we can do w*xtrn\n",
    "\n",
    "ypred = w*xtrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Let’s implement a loss function which is called as Mean Squared Error (MSE),**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this function we calculate J, our loss value, average of squared difference between real price values and predicted price values.\n",
    "\n",
    "\n",
    "* Implement MSE loss function which takes weight matrix, input matrix (xtrn or xtst) and ground truth prices (ytrn or ytst). \n",
    "\n",
    "\n",
    "* Make first parameter of loss function weight matrix, it’s not crucial, but make it a habit. \n",
    "\n",
    " \n",
    "* Helpful functions: **sum, mean, size, abs2, .*** You don’t have to use all of them. Use abs2 with dot syntax as abs2.(x) if you’re using it. Calculate the loss value for both splits by using your MSE loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(weigths,inputs,targets)\n",
    "    \n",
    "    preds = weigths*inputs\n",
    "    \n",
    "    loss = sum(abs2.(targets-preds))/size(inputs)[2]\n",
    "    \n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593.5506213087656"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(w,xtrn,ytrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### it's quite higher than the example in the practice document. This reason behind that might be that I did not normalize the targets?\n",
    "\n",
    "#### no it wasnt... index starts with 1 in julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let’s find in how many of them, the model predicts the price with an error less than average error. Measure the absolute difference between the predicted price and correct price for each neighborhood and compare those differences with the square root of the loss value calculated in previous exercise. Use sqrt function (with dot syntax, e.g. sqrt.(x)) to take square roots. Perform this step for only training set. The result should be 108."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.362894354094415"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE = sqrt(loss(w,xtrn,ytrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((ytrn-w*xtrn).-SE .< 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is something wrong! But what?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
